{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n",
    "This notebook shows the process of training a model.\n",
    "Configuration of the model is defined in the `config` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing can be slow due to large packages (`torch`). Please wait...\n",
      "Importing done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing can be slow due to large packages (`torch`). Please wait...\")\n",
    "\n",
    "# Added `noqa: E402` to suppress warning about the import order when linting\n",
    "import torch\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from argparse import ArgumentParser     # noqa: E402\n",
    "from pathlib import Path                # noqa: E402\n",
    "from tqdm.notebook import tqdm   # displays a progress bar\n",
    "from typing import Dict, Any, Optional\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "# import ipywidgets as widgets\n",
    "# from IPython.display import display\n",
    "from pprint import pprint\n",
    "\n",
    "from config.config_loader import load_config            # noqa: E402\n",
    "from utils.makepath import makepath as mkp               # noqa: E402\n",
    "# from data_lib.turtle_dataset_constructor \\\n",
    "#     import TurtleDatasetConstructor                     # noqa: E402\n",
    "from scripts.mri.pdhg_net_trainer import PdhgNetTrainer     # noqa: E402\n",
    "# from scripts.model_loader import ModelLoader            # noqa: E402\n",
    "\n",
    "print(\"Importing done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make sure we know the relative path to the root of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scripts',\n",
       " 'requirements.txt',\n",
       " 'mri.egg-info',\n",
       " 'venv',\n",
       " 'README.md',\n",
       " 'figures',\n",
       " 'config',\n",
       " 'LICENSE',\n",
       " 'utils',\n",
       " 'networks',\n",
       " 'tmp',\n",
       " 'dyn_mri_test.py',\n",
       " '.gitignore',\n",
       " 'gradops',\n",
       " 'pyproject.toml',\n",
       " 'gifs',\n",
       " 'data',\n",
       " 'pdhg',\n",
       " 'data_lib',\n",
       " 'wandb',\n",
       " 'encoding_objects',\n",
       " '.git']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Root directory of the project is two levels up from this notebook.\n",
    "# Change this if the notebook is moved.\n",
    "num_levels_up = 2\n",
    "\n",
    "root_dir = mkp(\".\")\n",
    "for _ in range(num_levels_up):\n",
    "    root_dir = mkp(root_dir, \"..\")\n",
    "\n",
    "os.listdir(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's choose the configuration to use for training.\n",
    "We can pass the path to a configuration file, which is either a YAML or a JSON file.\n",
    "An example configuration file named `example_model_config` is provided in the `config` directory.\n",
    "It contains the configuration for a tiny version of the U-TGV type-2 model.\n",
    "\n",
    "Another way is to pass a dictionary directly to the `config` parameter.\n",
    "\n",
    "Finally, there are options to simply state the model type.\n",
    "Here we have three options: `u_tv`, `u_tgv_type_1`, and `u_tgv_type_2`.\n",
    "They correspond to the U-TV, U-TGV type-1, and U-TGV type-2 models, respectively.\n",
    "The details of these models are as described in the report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config choice: ../../config/example_model_config.yaml\n"
     ]
    }
   ],
   "source": [
    "class MyArgs:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config,\n",
    "            output_dir = None,\n",
    "            device = \"cpu\",\n",
    "            logs_local: bool = True,\n",
    "            uses_wandb: bool = False\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.output_dir = output_dir\n",
    "        self.device = device\n",
    "        self.logs_local = logs_local\n",
    "        self.uses_wandb = uses_wandb\n",
    "\n",
    "# TODO: Set the model configuration here.\n",
    "args = MyArgs(\n",
    "    # TODO: Make sure the path is correct.\n",
    "    # Modify the config file or pass a different one if needed\n",
    "    config=mkp(root_dir, \"config\", \"example_model_config.yaml\"),\n",
    "    # config=mkp(root_dir, \"config\", \"example_model_config.yml\"),\n",
    "\n",
    "    # # Actual U-TV model in the report\n",
    "    # config=\"u_tv\",\n",
    "\n",
    "    # # Actual U-TGV type-1 model in the report\n",
    "    # config=\"u_tgv_type_1\",\n",
    "\n",
    "    # # Actual U-TGV type-2 model in the report\n",
    "    # config=\"u_tgv_type_2\",\n",
    "\n",
    "    # # Direct the output to a different directory if needed\n",
    "    # output_dir=mkp(root_dir, \"your_output_directory\"),\n",
    "    # output_dir=mkp(root_dir, \"tmp\", \"example_model\")\n",
    "\n",
    "    # Change the device if needed\n",
    "    # device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    # device=\"cpu\",\n",
    "    # device=\"mps\",  # Apple GPU\n",
    ")\n",
    "\n",
    "print(f\"Config choice: {args.config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the config if needed. Here we will reduce the U-Net size and use a small number of samples and epochs to demonstrate the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded from file ../../config/example_mri_tgv_config.yaml\n"
     ]
    }
   ],
   "source": [
    "# config = load_config(args.config, root_dir=root_dir, is_training=True)\n",
    "config_file_path = mkp(root_dir, \"config\", \"example_mri_tgv_config.yaml\")\n",
    "# with open(config_file_path, \"r\") as f:\n",
    "#     config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "# config = yaml.load(open(config_file_path, \"r\"), Loader=yaml.FullLoader)\n",
    "config = load_config(config_file_path, root_dir=root_dir, is_training=True)\n",
    "\n",
    "config[\"data\"][\"train_num_samples\"] = 10\n",
    "config[\"data\"][\"val_num_samples\"] = 10\n",
    "\n",
    "# config[\"unet\"][\"init_filters\"] = 32\n",
    "\n",
    "config[\"train\"][\"num_epochs\"] = 10\n",
    "\n",
    "# config[\"device\"] = \"cpu\"\n",
    "# config[\"device\"] = \"cuda\"   # Nvidia\n",
    "# config[\"device\"] = \"mps\"    # Apple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Let's instantiate the trainer with the chosen configuration and model type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded from dict\n",
      "Trainer initialized.\n",
      "Output directory: ../../tmp/example_mri_tgv\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "trainer = PdhgNetTrainer(\n",
    "    config_choice=config, tqdm=tqdm, device=args.device)\n",
    "if args.output_dir is not None:\n",
    "    trainer.config[\"log\"][\"save_dir\"] = args.output_dir\n",
    "print(f\"Output directory: {trainer.config['log']['save_dir']}\")\n",
    "print(f\"Device: {trainer.config['device']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the path to the data is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path: ../../tmp/mri\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data path: {trainer.config['data']['data_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log the progress\n",
    "\n",
    "We need to create the log files to log the training loss and validation loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '../../tmp/example_mri_tgv/train_epoch_metrics.csv' already exists.\n",
      "Overwriting the file...\n",
      "Creating file '../../tmp/example_mri_tgv/train_epoch_metrics.csv'...\n",
      "File '../../tmp/example_mri_tgv/train_intermediate_metrics.csv' already exists.\n",
      "Overwriting the file...\n",
      "Creating file '../../tmp/example_mri_tgv/train_intermediate_metrics.csv'...\n",
      "File '../../tmp/example_mri_tgv/val_epoch_metrics.csv' already exists.\n",
      "Overwriting the file...\n",
      "Creating file '../../tmp/example_mri_tgv/val_epoch_metrics.csv'...\n",
      "File '../../tmp/example_mri_tgv/val_intermediate_metrics.csv' already exists.\n",
      "Overwriting the file...\n",
      "Creating file '../../tmp/example_mri_tgv/val_intermediate_metrics.csv'...\n",
      "Logging options initialized.\n",
      "Logger initialized.\n"
     ]
    }
   ],
   "source": [
    "trainer.init_logger(force_overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new model...\n",
      "Norm of operator A: 1\n",
      "Norm of gradient operator nabla: 2.8284270763397217\n",
      "L: 3.0\n",
      "Model initialized. Model device: cpu.\n",
      "Number of trainable parameters: 517477.\n",
      "Model size: 1.97 MB.\n"
     ]
    }
   ],
   "source": [
    "trainer.init_pdhg_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the loss function and training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss function: MSELoss\n",
      "Training for 10 epochs, starting from epoch 0.\n",
      "Training options initialized.\n"
     ]
    }
   ],
   "source": [
    "trainer.init_training_options()\n",
    "\n",
    "# # Re-adjust if needed\n",
    "# trainer.num_epochs = 2\n",
    "# print(f\"Number of epochs adjusted to: {trainer.num_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "imgs_true_complex.shape: torch.Size([3452, 320, 320])\n",
      "\n",
      "min_abs_val: 4.898726047031232e-07\n",
      "max_abs_val: 2.58732533454895\n",
      "Training dataset size: 10\n",
      "Validation dataset size: 10\n",
      "Test dataset size: 302\n",
      "type of training_dataset: <class 'torch.utils.data.dataset.Subset'>\n",
      "type of validation_dataset: <class 'torch.utils.data.dataset.Subset'>\n",
      "type of test_dataset: <class 'torch.utils.data.dataset.Subset'>\n",
      "Data loaded.\n"
     ]
    }
   ],
   "source": [
    "trainer.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Log the configuration\n",
    "\n",
    "For easy future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving config in ../../tmp/example_mri_tgv...\n",
      "Config saved\n"
     ]
    }
   ],
   "source": [
    "# Store config and other logs if specified.\n",
    "if args.logs_local:\n",
    "    trainer.logger.log_config_local(trainer.pdhg_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Log to WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WandB for logging if specified.\n",
    "if args.uses_wandb:\n",
    "    trainer.logger.init_wandb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model will be saved in ../../tmp/example_mri_tgv.\n",
      "Training started for 10 epochs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32adff9bf3b4a2c84ab4833b5745415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d123af34e744f458d1c1ed170c2a38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceleration_factor_R: 5\n",
      "standard_deviation_sigma: 0.1454569458961487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/GIT/image-denoising-unet-tv-tgv/venv/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at ../aten/src/ATen/native/Copy.cpp:300.)\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Start training.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/GIT/image-denoising-unet-tv-tgv/scripts/mri/pdhg_net_trainer.py:388\u001b[0m, in \u001b[0;36mPdhgNetTrainer.start_training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_training\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m#     train()\u001b[39;00m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;66;03m# except Exception as e:\u001b[39;00m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m#     print(f\"Exception occurred: {e}\")\u001b[39;00m\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mrun \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[0;32m/home/GIT/image-denoising-unet-tv-tgv/scripts/mri/pdhg_net_trainer.py:340\u001b[0m, in \u001b[0;36mPdhgNetTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# Model training\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpdhg_net\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 340\u001b[0m train_loss, train_psnr, train_ssim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    342\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlog_metrics(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_loss, train_psnr, train_ssim)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m train_loss, train_psnr, train_ssim\n",
      "File \u001b[0;32m/home/GIT/image-denoising-unet-tv-tgv/scripts/mri/pdhg_net_trainer.py:296\u001b[0m, in \u001b[0;36mPdhgNetTrainer.perform_epoch\u001b[0;34m(self, data_loader, action)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data_loader)), leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    295\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_iter)\n\u001b[0;32m--> 296\u001b[0m     loss_value, psnr, ssim \u001b[38;5;241m=\u001b[39m \u001b[43mperform_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_value\n\u001b[1;32m    298\u001b[0m     running_psnr \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m psnr\n",
      "File \u001b[0;32m/home/GIT/image-denoising-unet-tv-tgv/scripts/mri/pdhg_net_trainer.py:249\u001b[0m, in \u001b[0;36mPdhgNetTrainer.perform_training_iteration\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_training_iteration\u001b[39m(\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m, sample: Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]\n\u001b[1;32m    245\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;66;03m# Zero your gradients for every batch! TODO: Why?\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 249\u001b[0m     loss, psnr, ssim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m!=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem():\n",
      "File \u001b[0;32m/home/GIT/image-denoising-unet-tv-tgv/scripts/mri/pdhg_net_trainer.py:205\u001b[0m, in \u001b[0;36mPdhgNetTrainer.perform_iteration\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m    200\u001b[0m undersampled_kdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mapply_A(\n\u001b[1;32m    201\u001b[0m     x_true, csm, undersampling_k_mask)\n\u001b[1;32m    203\u001b[0m undersampled_kdata_noisy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_random_k_noise(\n\u001b[1;32m    204\u001b[0m     undersampled_kdata, undersampling_k_mask)\n\u001b[0;32m--> 205\u001b[0m x_corrupted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_AH\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mundersampled_kdata_noisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mundersampling_k_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m x_reconstructed, reg_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpdhg_net(\n\u001b[1;32m    208\u001b[0m     x_corrupted,\n\u001b[1;32m    209\u001b[0m     undersampled_kdata_noisy,\n\u001b[1;32m    210\u001b[0m     undersampling_k_mask,\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    212\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mmse_loss(\n\u001b[1;32m    213\u001b[0m     torch\u001b[38;5;241m.\u001b[39mview_as_real(x_reconstructed),\n\u001b[1;32m    214\u001b[0m     torch\u001b[38;5;241m.\u001b[39mview_as_real(x_true)\n\u001b[1;32m    215\u001b[0m )\n",
      "File \u001b[0;32m/home/GIT/image-denoising-unet-tv-tgv/encoding_objects/cart_2d_enc_obj.py:69\u001b[0m, in \u001b[0;36mCart2DEncObj.apply_AH\u001b[0;34m(self, k, csm, mask)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_AH\u001b[39m(\u001b[38;5;28mself\u001b[39m, k, csm, mask):\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_CH(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_EH(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m), csm)\n",
      "File \u001b[0;32m/home/GIT/image-denoising-unet-tv-tgv/encoding_objects/cart_2d_enc_obj.py:61\u001b[0m, in \u001b[0;36mCart2DEncObj.apply_mask\u001b[0;34m(self, k, mask)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_mask\u001b[39m(\u001b[38;5;28mself\u001b[39m, k, mask):\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m k\n",
      "File \u001b[0;32m/home/GIT/image-denoising-unet-tv-tgv/venv/lib/python3.10/site-packages/torch/utils/_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "# Start training.\n",
    "start_time = time()\n",
    "trainer.start_training()\n",
    "end_time = time()\n",
    "print(f\"Training took {end_time - start_time} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
